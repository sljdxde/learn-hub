# 背景
反欺诈解决方案中，需要提供一个用于黑白名单管理的平台，此项目应运而生。项目需提供名单的文件导入、手动录入、修改、删除、查询和比对验证等功能。
# 需求
这里细化一下需求：

1. 支持系统上创建黑、白名单；且黑名单下的标签需要有有效期概念
2. 支持黑、白名单批量导入
3. 支持从kafka中消费数据，新增/删除/修改 黑白名单
4. 服务需要支持分布式及高可用
5. kafka消费，需要提供可观测特性
6. 服务需要记录名单变更记录
7. 名单清单需要同时存在于数据库和缓存，因此需要具备数据库与缓存的比对能力
# 功能点
针对上述7点主要需求（既包括功能，也包括性能），说一下具体解法：

1. 系统提供接口，在名单-标签这个数据结构下提供过期时间字段
2. 系统提供csv导入功能，用户提交后异步响应请求，后台则将名单发送至kafka
3. kafka消费过程中，需要注意的是，如果消费失败，应该具备必要的重试机制以及死信队列能力（重试达到上限）
4. 由于服务引入了kafka，因此分布式和高可用都可以用过zk实现。在zk上注册顺序临时节点，各个服务监听，尤其可以得到主服务和从服务。当主服务挂掉时，从服务自动升级成主服务。同时，使用顺序临时节点的另一个好处是防止脑裂的出现。
5. kafka消费的可观测性，主要是通过观测lag实现。在不考虑grafana+prometheus的条件下，服务内部需要提供一个查询lag的接口
6. 当名单记录出现：增、删、改时，产生对应记录的topic，发送至kafka
7. 在进行数据库和缓存比对时，由于拿取的是数据库快照，因此此时应该暂停掉名单服务的所有写操作，保证数据一致。比对操作是通过定时任务实现的，由于服务是分布式的，因此还需要有分布式锁保证只有一个节点执行任务（不引入quartz）
# 设计
## 中间件

- 数据库：MySQL
- 缓存：Aerospike
- 消息队列：kafka
- 分布式：zk
## 数据结构
### 缓存

- 名单缓存结构
```
名单类型_域名:{
    //标签
    tags:{//标签编码,过期时间
        “code1”:123123123,
        “code2”:123123123
    },
    //对比标识
    diff:””
}
```
### 数据库

- 名单类型表
| **字段** | **字段名** |
| --- | --- |
| type | 类型 |
| name | 名称 |

```sql
CREATE TABLE `t_dpi_type` (
  `type` varchar(32) NOT NULL COMMENT '类型',
  `name` varchar(32) NOT NULL COMMENT '类型名称'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT '名单类型表';
```
目前设置三种名单类型：

| 域名白名单 | whitelist |
| --- | --- |
| 银行名单 | bank |
| 黑名单 | black |

- 名单标签表
| **字段** | **字段名** |
| --- | --- |
| name | 标签名称 |
| code | 编码 |
| source | 来源,1=内部，2=外部 |

```sql
CREATE TABLE `t_dpi_tag` (
    `name` varchar(64) NOT NULL COMMENT '标签名称',
    `code` varchar(32) NOT NULL COMMENT '编码',
    `source` TINYINT(4) NOT NULL COMMENT '来源,1=内部，2=外部'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT '标签表';
```

- 名单表
```sql
CREATE TABLE `t_dpi_namelist` (
   `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '主键id',
   `nl_value` varchar(128) NOT NULL COMMENT '名单值',
   `type` varchar(32) NOT NULL COMMENT '类型',
   `tag` varchar(32) NOT NULL DEFAULT "" COMMENT '标签',
   `expire_time` bigint(13) DEFAULT NULL COMMENT '过期时间',
   `process_time` bigint(13) DEFAULT NULL COMMENT '处理时间',
   PRIMARY KEY (`id`),
   UNIQUE KEY `index_type_nl_value_tag` (`type`, `nl_value`, `tag`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='名单标签表';
```
### kafka

- 名单标准对象
| **字段** | **字段名** | **类型** |
| --- | --- | --- |
| nl_value | 名单值 | string |
| type | 类型 | string |
| tag | 标签 | string |
| expire | 过期时间 | long |
| oper_type | 操作（add  del） | string |
| source | 来源，1：内部；2或没有：外部 | int |
| process_time | 处理时间 | long |
| generation | 处理次数 | int |

这里需要简单说明一下部分字段用途：

- expire：用来标识tag的过期时间
- oper_type：用来标识该条记录时新增还是删除
- process_time：用来记录该条topic的**首次**处理时间
- generation：用来记录该条topic的处理次数

process_time和generation结合使用，用于记录消费失败的场景。这里举一个例子：
> 一条名单A，当初始被服务读取时，其process_time为空，generation为0。当处理过一次后，其process_time会被标记为处理时间（比如1682670086000），generation自增1（变为1）。但是该记录消费失败了（数据写入数据库失败），因此会被重新发回topic中进行重新排队。
> 当再次排到时，首先会比对generation是否大于预设的最大重试次数（比如3），当大于时，发送该条记录到死信队列；当不大于时，进行消费。此次假设消费成功，此时process_time有值，因此不再更新。在进行入库时，需要判断数据库中该名单该tag下是否有数据，如果有数据，需要比较process_time，避免覆盖掉后处理的数据。

## 接口
![image.png](https://cdn.nlark.com/yuque/0/2023/png/5369311/1682668835961-d51fde20-8938-4646-b375-6f0ea277e335.png#averageHue=%23fcfbfb&clientId=uc548b3ee-eda0-4&from=paste&height=265&id=u760f77ab&originHeight=438&originWidth=839&originalType=binary&ratio=1.6500000953674316&rotation=0&showTitle=false&size=1472818&status=done&style=none&taskId=uaf5c8f94-c427-456e-a957-01aefac9aaa&title=&width=508.48481909521746)
# 实现

- 具体代码就不贴了，哈哈
# 细节
设计已经完成，具体到代码实现层面，需要关注几个地方：

1. 线程池及任务的初始化
2. 使用`CuratorFramework`仅在zk的注册
3. 缓存更新时，使用乐观锁
4. 数据库更新时，事务的使用
