## 背景
最近的工作中接触到了大量性能调优方面的事务，这些都是之前工作中从未接触过的，这里简单总结一下。
## 方法论
总体而言，性能调优分为两部分，分别是客户端性能调优和服务端性能调优（针对CS架构），如果是管理平台等BS架构类型的系统，客户端就是浏览器，就是前端调优，而后端可以做的事情相当的少，就是服务端的调优。
### 调优手段
就目前的知识储备而言，我所了解的调优基本上如同程咬金的3板斧一般。

1. 劈脑袋之控制流量
2. 鬼剔牙之线程池与连接池适配
3. 掏耳朵之指标观测与参数调优

ok，下面分别针对上述3种方法进行详述。
#### 控制流量
当我们驾驶汽车行驶在马路上时，经常会遇到红绿灯。除了规范交通，红绿灯更为主要的作用是进行限流，控制路上行驶的车流量，避免拥塞。在计算机的世界里，也是处处存在着拥塞控制，最经典的当属TCP里的滑动窗口设计。
那么，同理，如果将服务端的处理能力看成道路，将客户端发送过来的请求看成汽车，很明显，也需要比较好的流量控制。
流量控制的手段有很多，这里按类型划分为两类，客户端限量和服务端限流。
客户端限流就是控制客户端流入的流量，通过限制流入来限制流出。最常见的方式是漏桶算法和令牌桶算法，如果考虑分布式场景，可能还需要引入中间件或者自己实现一套分布式限流。当然，这里还有更简单的方式，直接在客户端的方法入口增加信号量限流，这样就可以实现客户端的水平扩展。
服务端限流并不是常规意义上在服务端代码中实现限流，而是和客户端限流类似，限制流入的流量。**在客户端使用服务端连接池进行数据发送时，将大数据拆分成小数据进行发送。**比如将原本10000条的全量数据拆分成40个250条的数据，这样做可以显著提升TPS。
#### 线程池与连接池适配
在多核的世界里，多线程与线程池是提升性能的必备手段，通过引入多个线程并行处理，大大加快了处理速度。但是，线程数的设置也是很有讲究的。一般而言，会使用下面这个公式来推送：

- 假设服务器的逻辑CPU数是N
- 如果是IO密集型应用，那么线程数（核心线程数）会设置为2N
- 如果是CPU密集型应用，那么线程数（核心线程数）会设置为N+1

上述结论的具体推导可以百度一下，这里不再赘述。太大或太小的线程数都是不可取的，太小时无法充分利用多核的性能，而太大时会导致CPU大量开销在线程切换上，同样降低处理性能。
接下来，考虑CS架构中最为核心的一个组件，客户端连接池。一般来说，客户端连接池的底层是一个HTTP连接池，而在HTTP连接池中，下面的几个指标设置常常会直接影响服务性能

- MAX_CONNECTION_TOTAL：连接池最大连接数，用于控制整个服务端集群可以提供的连接数量，当超过这个数量时，连接就会被拒绝。
- ROUTE_MAX_COUNT：路由到某台主机的最大连接数。如果Max设置为800，集群中的主机数量为8，那么Route就可以设置为100，实现均分控制。当然具体的参数设置值与连接的负载均衡算法息息相关。
- CONNECTION_REQUEST_TIME_OUT：从连接池中获取连接的超时时间，这个值需要根据服务端处理请求的具体时长进行调整。如果处理时长比较长，那么建议设置的大一些，避免连接获取失败。
- CONNECTION_TIME_OUT：客户端和服务器建立连接的超时时间。正常的网络条件下，这个值一般而言都比较小，设置为3-5s即可。
- READ_TIME_OUT：客户端从服务器读取数据的超时时间。这个值比较重要，是处理时长，根据服务情况设置。建议在测试时，从默认设置（一般是6s），逐步提升，得到最终的响应时间。不可设置过大或过小，过小则超时未获取到数据，过大则导致会一直当服务端异常时，连接无法释放。
- CONNECTION_IDLE_TIME_OUT：连接空闲超时时间。
- 更加详细的连接池配置，参考[连接池配置详解](https://zhuanlan.zhihu.com/p/85524697#:~:text=HttpClient%E5%8F%8A%E5%85%B6%E8%BF%9E%E6%8E%A5%E6%B1%A0%E9%85%8D%E7%BD%AE%201%20%E6%95%B4%E4%B8%AA%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%AD%E6%9C%80%E5%A4%A7%E8%BF%9E%E6%8E%A5%E6%95%B0%20MAX_CONNECTION_TOTAL%20%3D%20800%202%20%E8%B7%AF%E7%94%B1%E5%88%B0%E6%9F%90%E5%8F%B0%E4%B8%BB%E6%9C%BA%E6%9C%80%E5%A4%A7%E5%B9%B6%E5%8F%91%E6%95%B0%EF%BC%8C%E6%98%AFMAX_CONNECTION_TOTAL%EF%BC%88%E6%95%B4%E4%B8%AA%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%AD%E6%9C%80%E5%A4%A7%E8%BF%9E%E6%8E%A5%E6%95%B0%EF%BC%89%E7%9A%84%E4%B8%80%E4%B8%AA%E7%BB%86%E5%88%86,%3D%205000%207%20%E8%BF%9E%E6%8E%A5%E7%A9%BA%E9%97%B2%E8%B6%85%E6%97%B6%EF%BC%8C%E6%B8%85%E6%A5%9A%E9%97%B2%E7%BD%AE%E7%9A%84%E8%BF%9E%E6%8E%A5%20CONNECTION_IDLE_TIME_OUT%20%3D%205000%20%E6%9B%B4%E5%A4%9A%E9%A1%B9%E7%9B%AE)。

那么所谓线程池与连接池适配是什么意思呢？举个例子来说，如果线程池的核心线程数配置为256，那么同时最高会有256个线程去执行。此时，如果连接池数量配置为128，那么就意味着会有剩余128个线程处于无法获取到连接的状态，出现不断的切换。**因此，建议在线程池与连接池的配置中，线程池数量小于等于连接池数量。**
#### 指标观测与参数调优
参数调优其实是一个相当枯燥的过程，需要不断的进行测试、修改参数这样的循环，最终找到一个临界点。在调优的过程中，针对指标的观测是验证参数调优好坏的关键。
指标观测，一般需要关注：CPU、IO、内存和网络，使用的工具包括：sar、iostat、nmon等等。如果测试过程中发现CPU负载始终维持在30% ～ 40%，那么就需要去检查程序中是不是限流控制的不对。如果观察到网络出现瓶颈，比如发送或者接收的包很大，达到网络带宽，那么就需要去调整发送的数据结构，或者调整发送的数据量。
## 实战
在实战环节中，讲2个最近做的案例，其中，案例1实现了TPS从200w到700w的飞跃，案例2实现了CPU负载从20%到80%的跳跃。
### 案例1
#### 场景概述
项目实现数据生产并将数据推送至服务端，该过程中会打印数据推送的TPS。
在项目的初次测试中，发现整体的TPS维持在100w到200w左右（当然，这里需要比较强劲的服务器，我们使用的服务器是物理机，256个逻辑CPU，内存512G），无论怎么修改线程数或者对过程进行优化，整体TPS都没有比较大的提升。
#### 优化点
这里的优化点就是大拆小，将数据拆分为400个一组的数据进行发送。最终实现了200w到700w的提升。
#### 指标观测
测试过程中，重点关注了CPU和内存的变化，因为数据推送时并没有持久化到磁盘上。如果有落盘环节，那么IO也是需要重点关注的指标，使用`sar -d`可以很方便的观测。
另外，测试过程中自己编写了shell脚本，记录了全过程的CPU及内存变化，对于后续的指标实时监测，也是非常有帮助的。
### 案例2
#### 场景概述
项目完成服务端数据进行查询，但是测试过程中发现，同时并发请求客户端时（使用jmeter或水平扩展分别请求），会直接导致连接池超时，将超时时间调长后同样会有该问题，且超时时间并未到达设置的时间。
分析问题后发现，在服务端需要完成多节点的数据merge操作，而超时会出现在merge中。
#### 优化点
将线程池数量和连接池数量调小，因为当客户端水平扩展后，服务端集群单个节点无法再承载这么大的流量，直接导致无连接可用，返回超时。
#### 
