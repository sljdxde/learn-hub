### 项目相关
1. 项目介绍
2. 项目亮点介绍（突出设计模式）
3. 用到哪些设计模式，怎么用的：策略 + 工厂，具体用法结合项目来谈
4. 还有哪些设计模式：门面、代理；享元；单例；

### 基础知识

1. 多线程 && 线程池配置
   1. 关键参数定义
      1. corePoolSize（默认为1）：核心线程数，一直存活。当线程数小于该值时，线程池会创建线程。可以设置超时关闭（allowCoreThreadTimeout）
      2. queueCapacity（Integer.MAX_VALUE）：当核心线程数达到最大时，新任务放在**任务队列**中，阻塞等待执行
      3. maxPoolSize（Integer.MAX_VALUE）：当线程数>=corePoolSize，且queueCapacity已满时，会创建新的线程来执行任务；当线程数=maxPoolSize，且任务队列已满时，会拒绝处理任务抛出异常（该拒绝方法可以自定义）
      4. keepAliveTime（空闲时间）：当线程空闲时间=keepAliveTime时，线程会关闭，直到线程数=核心线程数；当allowCoreThreadTimeout=true时，核心线程也会关闭
   2. 如何设置参数：需要根据几个值来确定，分别是tasks（每秒任务数），taskcost（任务消耗时间），responsetime（系统容忍的最大响应时间）
      1. corePoolSize：`threadcount = tasks/(1/taskcost) = tasks*taskcost =  (500~1000)*0.1 = 50~100 个线程。corePoolSize设置应该大于50`。根据二八定律，假定80%的指标，则每秒任务数小于800，**则corePoolSize设置为80**。
      2. queueCapacity：`(coreSizePool/taskcost)*responsetime`。计算可得 queueCapacity = 80/0.1*1 = 80。意思是队列里的线程可以等待1s，超过了的需要新开线程来执行切记不能设置为Integer.MAX_VALUE，这样队列会很大，线程数只会保持在corePoolSize大小，当任务陡增时，不能新开线程来执行，响应时间会随之陡增。
      3. maxPoolSize：`(max(tasks)- queueCapacity)/(responsetime/taskcost)`。计算可得 maxPoolSize = (1000-80)/10 = 92（最大任务数-队列容量）/每个线程容忍时间内的处理能力 = 最大线程数。
      4. rejectedExecutionHandler：根据具体情况来决定，任务不重要可丢弃，任务重要则要利用一些缓冲机制来处理
      5. keepAliveTime和allowCoreThreadTimeout采用默认通常能满足
2. sql更底层的原理，sql优化
   1. sql使用b+树索引的优点：b树是有序数组+平衡多叉树；b+树是有序数组链表+平衡多叉树。首先，b树是为了减少IO次数而生的，使用b树查询时，首先会使用二分查找找到对应的磁盘块，然后加载到内存中进行判断，判断查找路径应该走向哪里。但是如果是范围查询，需要不断返回根节点进行判断，增加了时间消耗。而b+树在b树的基础上，增加了前一个块指向后一个块的指针，因此无需返回根节点，直接可以找到下一个块的地址，很适合范围查询。
   2. 为什么不使用红黑树：因此索引存放在磁盘，每次读取时需要先加载到内存中，会产生IO消耗。红黑树是平衡二叉树，深度很大，因此需要多次加载；另外，红黑树无法充分利用局部性原理（逻辑上很近的节点物理上很远，因为底层是数据）。
   3. sql优化的步骤：
      1. 开启慢查日志
      2. 查询慢sql（默认执行时间超过0.05s的）
      3. explain查看执行计划：几个关键参数
         1. id、table、type、
      4. 优化（加索引）
   4. 索引类型及特点：
      1. all、index、range、ref、eq_ref、const
   5. sql主从同步执行过程：
      1. relay log
      2. 。。。
3. volatile的用途：
   1. 保证内存可见性：即线程A对volatile变量的修改，其他线程能得到的都是最新的
      1. **怎么保证的**：
> 所有线程的共享变量都存储在主内存中，每一个线程都有一个独有的工作内存，每个线程不直接操作
> 在主内存中的变量，而是将主内存上变量的副本放进自己的工作内存中，只操作工作内存中的数据。当修				
> 改完毕后，再把修改后的结果放回到主内存中。每个线程都只操作自己工作内存中的变量，无法直接访问
> 对方工作内存中的变量，线程间变量值的传递需要通过主内存来完成。
> 
> 上述的Java内存模型在单线程的环境下不会出现问题，但在多线程的环境下可能会出现脏数据，例如：如果有AB两个线程同时拿到变量i，进行递增操作。A线程将变量i放到自己的工作内存中，然后做+1操作，然而此时，线程A还没有将修改后的值刷回到主内存中，而此时线程B也从主内存中拿到修改前的变量i，也进行了一遍+1的操作。最后A和B线程将各自的结果分别刷回到主内存中，看到的结果就是变量i只进行了一遍+1的操作，而实际上A和B进行了两次累加的操作，于是就出现了错误。究其原因，是因为线程B读取到了变量i的脏数据的缘故。
> 
> 此时如果对变量i加上volatile关键字修饰的话，它可以保证当A线程对变量i值做了变动之后，会立即刷回到主内存中，而其它线程读取到该变量的值也作废，强迫重新从主内存中读取该变量的值，这样在任何时刻，AB线程总是会看到变量i的同一个值。

      2. **实现方式**：volatile可见性是通过汇编加上Lock前缀指令，触发底层的MESI缓存一致性协议来实现的。当然这个协议有很多种，不过最常用的就是MESI。
         1. M 修改（Modified）：此时缓存行中的数据与主内存中的数据不一致，数据只存在于本工作内存中。其他线程从主内存中读取共享变量值的操作会被延迟执行，直到该缓存行将数据写回到主内存后
         2. E 独享（Exclusive）：此时缓存行中的数据与主内存中的数据一致，数据只存在于本工作内存中。此时会监听其他线程读主内存中共享变量的操作，如果发生，该缓存行需要变成共享状态
         3. S 共享（Shared）：此时缓存行中的数据与主内存中的数据一致，数据存在于很多工作内存中。此时会监听其他线程使该缓存行无效的请求，如果发生，该缓存行需要变成无效状态
         4. I 无效（Invalid）：此时该缓存行无效
         5. 举个例子：
> 假如说当前有一个cpu去主内存拿到一个变量x的值初始为1，放到自己的工作内存中。此时它的状态就是独享状态E，然后此时另外一个cpu也拿到了这个x的值，放到自己的工作内存中。此时之前那个cpu会不断地监听内存总线，发现这个x有多个cpu在获取，那么这个时候这两个cpu所获得的x的值的状态就都是共享状态S。然后第一个cpu将自己工作内存中x的值带入到自己的ALU计算单元去进行计算，返回来x的值变为2，接着会告诉给内存总线，将此时自己的x的状态置为修改状态M。而另一个cpu此时也会去不断的监听内存总线，发现这个x已经有别的cpu将其置为了修改状态，所以自己内部的x的状态会被置为无效状态I，等待第一个cpu将修改后的值刷回到主内存后，重新去获取新的值。这个谁先改变x的值可能是同一时刻进行修改的，此时cpu就会通过底层硬件在同一个指令周期内进行裁决，裁决是谁进行修改的，就置为修改状态，而另一个就置为无效状态，被丢弃或者是被覆盖（有争论）。
> 当然，MESI也会有失效的时候，缓存的最小单元是缓存行，如果当前的共享数据的长度超过一个缓存行的长度的时候，就会使MESI协议失败，此时的话就会触发总线加锁的机制，第一个线程cpu拿到这个x的时候，其他的线程都不允许去获取这个x的值。

   2. 禁止指令重排序：典型使用场景，单例模式双重锁
```shell
public class Singleton {
		// 如果去掉volatile,可能会导致该单例模式失效
    // 具体原因是由于，instance = new Singleton() 不是原子操作
    // 因此在jvm阶段，可能会被重新排序
    // 期望的jvm是由下述3个阶段顺序执行：
    // 1.为instance分配内存
		// 2.初始化instance
		// 3.将instance变量指向分配的内存空间
    // 但是由于可能存在的指令重排，会导致3个步骤顺序不再确定。
    // 会出现先初始化，但是暂时没有分配内存的情况，
    // 此时，instante == null的判断失效，导致会初始化多个实例
    private volatile static Singleton instance;

    private Singleton() {}

    public static Singleton getInstance() {
        if (instance == null) {
            synchronized (Singleton.class) {
                if (instance == null) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```

   3. 不保证原子性：
```shell
public class Test {

    private static CountDownLatch countDownLatch = new CountDownLatch(1000);
    private volatile static int   num            = 0;

    public static void main(String[] args) {
        ExecutorService executor = Executors.newCachedThreadPool();
        for (int i = 0; i < 1000; i++) {
            executor.execute(() -> {
                try {
                    num++;
                } catch (Exception e) {
                    e.printStackTrace();
                } finally {
                    countDownLatch.countDown();
                }
            });
        }
        try {
            countDownLatch.await();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        executor.shutdown();
        System.out.println(num);
    }
}
```
因为num++是非原子操作，会触发MESI协议的失效动作，因此最终结果大概率不是1000。

5. synchronize的用法
- [synchronize用法](https://zhuanlan.zhihu.com/p/263398362)

6. currenthashmap的原理
- [currenthashmap](https://blog.csdn.net/qq_22343483/article/details/98510619)

7. Cap理论
- [CAP理论](https://www.cnblogs.com/mingorun/p/11025538.html)

8. 共识算法
9. jvm启动参数及调优

10. quartz框架原理

11. arthas用法

### 二面

1. Springboot Starter原理
- 答：
2. 项目中的亮点
- 答：设计模式；DDD；分布式事务
3. 简单写一个策略加工厂的demo
```java
public interface Food {
    private String name;
    public String getFoodName();
}

public class FoodFactory {
    
    private Food food;
    
    public String getFoodName() {
        return food.getFoodName();
    }

}

public class Hanburger implements Food {
    @Override
    public String getFoodName() {
        return "Hanburger";
    }
}

public class Pizza implements Food {
    @Override
    public String getFoodName() {
        return "pizza";
    }
}

// policy
public class PolicyContext() {
    
    public Food getPolicy(String context) {
        if (xxx) {
            return new Hanburger();
        } else {
            return new Pizza;
        }
    }
}

```
### 三面

1. MQ实现上下游消息一致性
- 答：
2. LRU的实现
- 思路一：使用array存储，每个node记录值和一个表示访问间隔的时间戳。每次有数据插入时，讲所有节点的时间戳+1，同时，将该数值对应的节点时间戳置0。每次淘汰时，淘汰时间戳最大的节点。
- 思路二：使用FIFO链表存储。每次插入数据时，将该数据移动到链表头部；每次有数据命中时，同样将该数据移动到链表头部；每次淘汰时，淘汰尾部节点。
- 思路三：使用链表+hashmap。判断是否存在时使用hashmap，其他思路均同于思路二。
- 思路四：参考redis中的实现 - [https://redis.io/topics/lru-cache](https://redis.io/topics/lru-cache)
- talk is cheap, show me the code
3. LRU的扩展
- [https://blog.csdn.net/elricboa/article/details/78847305](https://blog.csdn.net/elricboa/article/details/78847305)
4. 最近有看什么源码，简单讲讲
- 答：seata。XA和saga模式
5. 前序、中序、后序遍历，实现
